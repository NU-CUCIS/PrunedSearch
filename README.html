<!doctype html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<style>
body {
  font-family: Helvetica, arial, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  padding-top: 10px;
  padding-bottom: 10px;
  background-color: white;
  padding: 30px; }

body > *:first-child {
  margin-top: 0 !important; }
body > *:last-child {
  margin-bottom: 0 !important; }

a {
  color: #4183C4; }
a.absent {
  color: #cc0000; }
a.anchor {
  display: block;
  padding-left: 30px;
  margin-left: -30px;
  cursor: pointer;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0; }

h1, h2, h3, h4, h5, h6 {
  margin: 20px 0 10px;
  padding: 0;
  font-weight: bold;
  -webkit-font-smoothing: antialiased;
  cursor: text;
  position: relative; }

h1:hover a.anchor, h2:hover a.anchor, h3:hover a.anchor, h4:hover a.anchor, h5:hover a.anchor, h6:hover a.anchor {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA09pVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMy1jMDExIDY2LjE0NTY2MSwgMjAxMi8wMi8wNi0xNDo1NjoyNyAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNiAoMTMuMCAyMDEyMDMwNS5tLjQxNSAyMDEyLzAzLzA1OjIxOjAwOjAwKSAgKE1hY2ludG9zaCkiIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OUM2NjlDQjI4ODBGMTFFMTg1ODlEODNERDJBRjUwQTQiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OUM2NjlDQjM4ODBGMTFFMTg1ODlEODNERDJBRjUwQTQiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo5QzY2OUNCMDg4MEYxMUUxODU4OUQ4M0REMkFGNTBBNCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo5QzY2OUNCMTg4MEYxMUUxODU4OUQ4M0REMkFGNTBBNCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PsQhXeAAAABfSURBVHjaYvz//z8DJYCRUgMYQAbAMBQIAvEqkBQWXI6sHqwHiwG70TTBxGaiWwjCTGgOUgJiF1J8wMRAIUA34B4Q76HUBelAfJYSA0CuMIEaRP8wGIkGMA54bgQIMACAmkXJi0hKJQAAAABJRU5ErkJggg==) no-repeat 10px center;
  text-decoration: none; }

h1 tt, h1 code {
  font-size: inherit; }

h2 tt, h2 code {
  font-size: inherit; }

h3 tt, h3 code {
  font-size: inherit; }

h4 tt, h4 code {
  font-size: inherit; }

h5 tt, h5 code {
  font-size: inherit; }

h6 tt, h6 code {
  font-size: inherit; }

h1 {
  font-size: 28px;
  color: black; }

h2 {
  font-size: 24px;
  border-bottom: 1px solid #cccccc;
  color: black; }

h3 {
  font-size: 18px; }

h4 {
  font-size: 16px; }

h5 {
  font-size: 14px; }

h6 {
  color: #777777;
  font-size: 14px; }

p, blockquote, ul, ol, dl, li, table, pre {
  margin: 15px 0; }

hr {
  background: transparent url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAYAAAAECAYAAACtBE5DAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAyJpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNSBNYWNpbnRvc2giIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OENDRjNBN0E2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OENDRjNBN0I2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo4Q0NGM0E3ODY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo4Q0NGM0E3OTY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PqqezsUAAAAfSURBVHjaYmRABcYwBiM2QSA4y4hNEKYDQxAEAAIMAHNGAzhkPOlYAAAAAElFTkSuQmCC) repeat-x 0 0;
  border: 0 none;
  color: #cccccc;
  height: 4px;
  padding: 0;
}

body > h2:first-child {
  margin-top: 0;
  padding-top: 0; }
body > h1:first-child {
  margin-top: 0;
  padding-top: 0; }
  body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0; }
body > h3:first-child, body > h4:first-child, body > h5:first-child, body > h6:first-child {
  margin-top: 0;
  padding-top: 0; }

a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 {
  margin-top: 0;
  padding-top: 0; }

h1 p, h2 p, h3 p, h4 p, h5 p, h6 p {
  margin-top: 0; }

li p.first {
  display: inline-block; }
li {
  margin: 0; }
ul, ol {
  padding-left: 30px; }

ul :first-child, ol :first-child {
  margin-top: 0; }

dl {
  padding: 0; }
  dl dt {
    font-size: 14px;
    font-weight: bold;
    font-style: italic;
    padding: 0;
    margin: 15px 0 5px; }
    dl dt:first-child {
      padding: 0; }
    dl dt > :first-child {
      margin-top: 0; }
    dl dt > :last-child {
      margin-bottom: 0; }
  dl dd {
    margin: 0 0 15px;
    padding: 0 15px; }
    dl dd > :first-child {
      margin-top: 0; }
    dl dd > :last-child {
      margin-bottom: 0; }

blockquote {
  border-left: 4px solid #dddddd;
  padding: 0 15px;
  color: #777777; }
  blockquote > :first-child {
    margin-top: 0; }
  blockquote > :last-child {
    margin-bottom: 0; }

table {
  padding: 0;border-collapse: collapse; }
  table tr {
    border-top: 1px solid #cccccc;
    background-color: white;
    margin: 0;
    padding: 0; }
    table tr:nth-child(2n) {
      background-color: #f8f8f8; }
    table tr th {
      font-weight: bold;
      border: 1px solid #cccccc;
      margin: 0;
      padding: 6px 13px; }
    table tr td {
      border: 1px solid #cccccc;
      margin: 0;
      padding: 6px 13px; }
    table tr th :first-child, table tr td :first-child {
      margin-top: 0; }
    table tr th :last-child, table tr td :last-child {
      margin-bottom: 0; }

img {
  max-width: 100%; }

span.frame {
  display: block;
  overflow: hidden; }
  span.frame > span {
    border: 1px solid #dddddd;
    display: block;
    float: left;
    overflow: hidden;
    margin: 13px 0 0;
    padding: 7px;
    width: auto; }
  span.frame span img {
    display: block;
    float: left; }
  span.frame span span {
    clear: both;
    color: #333333;
    display: block;
    padding: 5px 0 0; }
span.align-center {
  display: block;
  overflow: hidden;
  clear: both; }
  span.align-center > span {
    display: block;
    overflow: hidden;
    margin: 13px auto 0;
    text-align: center; }
  span.align-center span img {
    margin: 0 auto;
    text-align: center; }
span.align-right {
  display: block;
  overflow: hidden;
  clear: both; }
  span.align-right > span {
    display: block;
    overflow: hidden;
    margin: 13px 0 0;
    text-align: right; }
  span.align-right span img {
    margin: 0;
    text-align: right; }
span.float-left {
  display: block;
  margin-right: 13px;
  overflow: hidden;
  float: left; }
  span.float-left span {
    margin: 13px 0 0; }
span.float-right {
  display: block;
  margin-left: 13px;
  overflow: hidden;
  float: right; }
  span.float-right > span {
    display: block;
    overflow: hidden;
    margin: 13px auto 0;
    text-align: right; }

code, tt {
  margin: 0 2px;
  padding: 0 5px;
  white-space: nowrap;
  border: 1px solid #eaeaea;
  background-color: #f8f8f8;
  border-radius: 3px; }

pre code {
  margin: 0;
  padding: 0;
  white-space: pre;
  border: none;
  background: transparent; }

.highlight pre {
  background-color: #f8f8f8;
  border: 1px solid #cccccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px; }

pre {
  background-color: #f8f8f8;
  border: 1px solid #cccccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px; }
  pre code, pre tt {
    background-color: transparent;
    border: none; }

sup {
    font-size: 0.83em;
    vertical-align: super;
    line-height: 0;
}
* {
	-webkit-print-color-adjust: exact;
}
@media screen and (min-width: 914px) {
    body {
        width: 854px;
        margin:0 auto;
    }
}
@media print {
	table, pre {
		page-break-inside: avoid;
	}
	pre {
		word-wrap: break-word;
	}
}
</style>
<title>Pruned Search</title>
<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax:{inlineMath:[['$$$','$$$']]}});</script><script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
<h1>Pruned Search</h1>

<p>Pruned Search is an enhanced searching algorithm for general optimization. It combines the concept of importance ranking and dimension reduction
and generalize them into meta-heuristics, in order to help better search for optimal objectives.</p>

<p>As any optimization tool, what the algorithm requires as inputs are a set of control variables x, an objective function in the form of y=f(x)
where y is the target of optimization, and a set of constraints as bounds and/or functions of x.</p>

<p>Pruned Search performs four steps of work:</p>

<pre><code>1. First it takes the objective function and variable constraints to generate a set of data, composed of "good" samples and "bad" samples.
"Good" samples are those having high objective values if the target is to optimize, and vice versa. "Bad" samples are values of the other 
extreme, included to form a opposing force for data mining algorithms. Samples include x values and y value (later simplified into 0 and 1)
to denote "bad" and "good" label of samples.

2. Secondly it takes the data samples generated by (1), performs feature ranking to determine a best search order of variables, from the 
most important to the least.

3. In parallel it also takes the data samples generated by (1) to build a classification tree to classify good and bad examples. After a 
classification tree is built fully, it parses the nodes to extract paths that contribute to the desired target. Variable regions can be 
narrowed by taking consideration of the threshold values used along the path. 

4. With a more superior variable order to perform the search, and reduced regions for each variable, a regular pattern search algorithm 
can be seen enhanced in both efficiency and accuracy. 
</code></pre>

<h2>Related Publications</h2>

<p>[1] Ruoqian Liu, Abhishek Kumar, Zhengzhang Chen, Ankit Agrawal, Veera Sundararaghavan, and Alok Choudhary. A Predictive Machine Learning Approach for Microstructure Optimization and Materials Design. Nature Scientific Reports, 5, 11551; doi: 10.1038/srep11551. 2015.</p>

<p>[2] Ruoqian Liu, Ankit Agrawal, Wei-keng Liao, and Alok Choudhary. Search space preprocessing in solving complex optimization problems. Big Data (Big Data), 2014 IEEE International Conference on, pp. 1-5.</p>

<p>[3] Ruoqian Liu, Ankit Agrawal, Wei-keng Liao, Zhengzhang Chen, and Alok Choudhary. Pruned search: A machine learning based meta-heuristic approach for constrained continuous optimization. Contemporary Computing (IC3), 2015 Eighth International Conference on, Noida, 2015, pp. 13-18.</p>

<h2>Implementation</h2>

<p>All scripts are written in MatLab and Python.</p>

<p>The four steps of work are implemented separately in three program files, as follows:</p>

<pre><code>1. Step 1, data generation. Programs are included in source/datagen/
    - Script names starting with "exp_" are those used to generate data, with choices of different randomization methods, and constraint functions. 
    - For example, exp_randEvery5Gen_E.m generates data using a method "Random Every Five" (described in [1]) with the objective and constraints given by materials property E.
    - In it, objective function SeparateOptE and the corresponding constraints (hardcoded) are used.
    - Similarly, exp_randGreedyGen* implements the method "Random Greedy", exp_randIntervalGen* implements "Random Interval", exp_randSmallPartition* implements "Random Small Partition" [1]
    - The output of this step is the generated data. At the end of each exp_* script specifies where the data is saved, usually as .mat file at data/

2. Step 2 and Step 3, meta-heuristics generation. Program to perform this step is source/train_model.py
    - The function feature_selection performs said Step 2 the importance ranking of features.
    - The function calc_feature_ranges performs said Step 3 the search range reduction.
    - The output of this program is saved in a .mat file, usually at model_output/, that contains two variables
        * 'sorted_feature_ids': an array of feature ids from the most important to the least important. For example, [3, 5, 4, 2, ...] would mean that feature 3 is the most important feature (to be searched first)
        * 'feature_ranges': a 2D array of feature ranges to search from. For example, [[0.1,0.3], [0.25, 0.36], ...] means that the first feature is best to be searched within a value range between 0.1 and 0.3

3. Step 4, enhanced optimization. Program to perform this step is source/patternSearch_min.m and source/trustRegion_min.m
    - The two scripts each contain a function to be called with a objective function handle.
    - For example, in a Matlab shell, call patternSearch_min(@SeparateOptY)
    - The output of this program is the best value found, along with certain intermediate printouts to indicate running progress. 
</code></pre>

<h2>Requirements</h2>

<p>MatLab 7.6 (or higher)
Python 2.7
Numpy 1.4 (or higher)
Scipy 0.7 (or higher)
Sklearn 0.14 (or higher to support more feature selection methods)</p>

<h2>How to run it</h2>

<p>Three corresponding demo scripts are included in demo/</p>

<pre><code>1. Step 1: directly run demo/exp_rand_demo.m will generate data and save in data/data_demo.mat

    - First, specify your local matlab location, like this
        MATLAB=/usr/local/MATLAB/R2012a/bin/glnxa64/MATLAB
    - Run the Matlab demo code for Step 1, like this
        $MATLAB -r "run source/datagen/exp_rand_demo"
    - Sample output:

    Program Step 1: Random data generation.
    Property function used:
        @SeparateOptE

    Specified size of data to be generated:
        1000

    Data of size 600 (rows) x 77 (column) are generated, and saved at ../../data/data_demo.mat


2. Step 2 and Step 3: run source/train_model.py and specify --input_data as data generated from 1. 
It will generate variable order and reduced range and save in model_output/modelout.mat

    - Run like this:
        python source/train_model.py --input_data data/data_demo.mat --output_data model_output/demo_modelout.mat

    - Sample output:

    Feature selection   cost 0.0032 seconds
    Fitting the decision tree and compute feature range   cost 0.1450 seconds

3. Step 4: run source/patternSearch_demo.m 
It will take data generated from 2 and printout the best value found at the end of program.

    - Run like this:
        $MATLAB -r "run source/patternSearch_demo"

    - Sample output (This optimization search could take a while):

     #### Current Varialbe --------------- 34 
     #### Current Varialbe --------------- 57
     #### Current Varialbe --------------- 49
     #### Current Varialbe --------------- 69
     ...
     #### Program ends. Best value found: -3.430972
</code></pre>

<p>Examples of output printouts by directly running the three demo code are included in
    demo_screen_1.log
    demo_screen_2.log
    demo_screen_3.log</p>

<p>A bash script incorporating all above steps is written, namely run_demo.sh
To run all three steps at once, run like this: ./run_demo.sh</p>

<h2>Auxiliary scripts</h2>

<ul>
<li>SeparateOptY.m: an example of objective function to minimize.</li>
</ul>


<h2>Acknowledgement</h2>

<p>This work is supported by AFOSR (Air Force Office of Scientific Research), Department of Defense (DOD) under Award No. FA9550-12-1-0458</p>

<h2>Contact</h2>

<p>Rosanne Liu (mimosavvy@gmail.com)</p>
<p>Ankit Agrawal (ankitag@eecs.northwestern.edu)</p>
<p>Alok Choudhary (choudhar@eecs.northwestern.edu)</p>
</body>
</html>
